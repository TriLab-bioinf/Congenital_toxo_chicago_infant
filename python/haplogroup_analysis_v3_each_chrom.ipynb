{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxoplasma gondii Haplogroup Analysis\n",
    "\n",
    "This notebook analyzes SNP data from Toxoplasma gondii strains to identify haplogroups based on allele patterns across the genome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches # For custom legends\n",
    "from collections import Counter\n",
    "import time # To time potentially long operations\n",
    "\n",
    "# Define file paths\n",
    "snp_file = 'snp.merge.txt'\n",
    "clade_file = 'Strain_clades.xlsx'\n",
    "genome_file = 'genome_table_ME49.txt'\n",
    "output_plot_file = 'haplogroups.pdf'\n",
    "\n",
    "# Load SNP data\n",
    "# Low_memory=False can help with mixed types, common in large SNP tables\n",
    "print(f\"Loading SNP data from {snp_file}...\")\n",
    "try:\n",
    "    snp_data = pd.read_csv(snp_file, sep='\\t', low_memory=False)\n",
    "    print(\"SNP data loaded successfully.\")\n",
    "    print(f\"Shape: {snp_data.shape}\")\n",
    "    # Rename the first two columns for clarity based on inspection\n",
    "    snp_data.rename(columns={snp_data.columns[0]: 'Chromosome', snp_data.columns[1]: 'Position'}, inplace=True)\n",
    "    # Ensure Position is numeric\n",
    "    snp_data['Position'] = pd.to_numeric(snp_data['Position'], errors='coerce')\n",
    "    snp_data.dropna(subset=['Position'], inplace=True)\n",
    "    snp_data['Position'] = snp_data['Position'].astype(int)\n",
    "    print(\"First 5 rows of SNP data:\")\n",
    "    print(snp_data.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {snp_file}\")\n",
    "    snp_data = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading {snp_file}: {e}\")\n",
    "    snp_data = None\n",
    "\n",
    "# Load Clade information\n",
    "print(f\"\\nLoading Clade data from {clade_file}...\")\n",
    "try:\n",
    "    # Using the confirmed sheet name and column names\n",
    "    clade_info = pd.read_excel(clade_file, sheet_name='Sheet1')\n",
    "    # Ensure the specified columns exist\n",
    "    if 'StrainID' in clade_info.columns and 'Clade' in clade_info.columns:\n",
    "        print(\"Clade data loaded successfully.\")\n",
    "        print(f\"Shape: {clade_info.shape}\")\n",
    "        # Convert StrainID to string for reliable comparison\n",
    "        clade_info['StrainID'] = clade_info['StrainID'].astype(str)\n",
    "        # Standardize Clade names (e.g., convert to string, remove whitespace)\n",
    "        clade_info['Clade'] = clade_info['Clade'].astype(str).str.strip()\n",
    "        print(\"First 5 rows of Clade data:\")\n",
    "        print(clade_info.head())\n",
    "    else:\n",
    "        print(f\"Error: Required columns 'StrainID' or 'Clade' not found in {clade_file}, Sheet1.\")\n",
    "        print(f\"Available columns: {clade_info.columns.tolist()}\")\n",
    "        clade_info = None\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {clade_file}\")\n",
    "    clade_info = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading {clade_file}: {e}\")\n",
    "    clade_info = None\n",
    "\n",
    "# Load Genome information\n",
    "print(f\"\\nLoading Genome table from {genome_file}...\")\n",
    "try:\n",
    "    genome_info = pd.read_csv(genome_file, sep='\\t', header=None, names=['Chromosome', 'Length'])\n",
    "    print(\"Genome table loaded successfully.\")\n",
    "    print(f\"Shape: {genome_info.shape}\")\n",
    "    print(\"First 5 rows of Genome table:\")\n",
    "    print(genome_info.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {genome_file}\")\n",
    "    genome_info = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading {genome_file}: {e}\")\n",
    "    genome_info = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing & Merging\n",
    "\n",
    "Here we preprocess the data:\n",
    "- Identify common strains between SNP data and Clade info.\n",
    "- Filter SNP data to include only these common strains.\n",
    "- Transpose the SNP data so strains are rows and SNPs are columns.\n",
    "- Add Clade information to the transposed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_snp_data = None\n",
    "snp_positions_df = None # To store original SNP positions\n",
    "\n",
    "if snp_data is not None and clade_info is not None:\n",
    "    print(\"\\nStarting Data Preprocessing and Merging...\")\n",
    "    \n",
    "    # Identify strain columns in snp_data (all columns except the first two)\n",
    "    strain_columns_snp = snp_data.columns[2:].tolist()\n",
    "    print(f\"Found {len(strain_columns_snp)} strain columns in SNP data.\")\n",
    "    \n",
    "    # Get strain IDs from clade_info\n",
    "    strain_ids_clade = set(clade_info['StrainID'].astype(str).unique())\n",
    "    print(f\"Found {len(strain_ids_clade)} unique strain IDs in Clade data.\")\n",
    "    \n",
    "    # Find common strains\n",
    "    common_strains = list(set(strain_columns_snp) & strain_ids_clade)\n",
    "    print(f\"Found {len(common_strains)} common strains between SNP and Clade data.\")\n",
    "    \n",
    "    # Report discrepancies\n",
    "    strains_only_in_snp = list(set(strain_columns_snp) - strain_ids_clade)\n",
    "    strains_only_in_clade = list(strain_ids_clade - set(strain_columns_snp))\n",
    "    if strains_only_in_snp:\n",
    "        print(f\"Warning: {len(strains_only_in_snp)} strains found only in SNP data (will be excluded): {strains_only_in_snp[:10]}...\")\n",
    "    if strains_only_in_clade:\n",
    "        print(f\"Warning: {len(strains_only_in_clade)} strains found only in Clade data: {strains_only_in_clade[:10]}...\")\n",
    "        \n",
    "    if not common_strains:\n",
    "        print(\"Error: No common strains found between SNP data and Clade info. Cannot proceed.\")\n",
    "    else:\n",
    "        # Store original SNP positions before filtering columns\n",
    "        snp_positions_df = snp_data[['Chromosome', 'Position']].copy()\n",
    "        snp_positions_df.set_index(['Chromosome', 'Position'], inplace=True)\n",
    "        \n",
    "        # Filter snp_data to keep only common strains and identifier columns\n",
    "        snp_data_filtered = snp_data[['Chromosome', 'Position'] + common_strains].copy()\n",
    "        \n",
    "        # Set Chromosome and Position as index\n",
    "        snp_data_filtered.set_index(['Chromosome', 'Position'], inplace=True)\n",
    "        \n",
    "        # Transpose the DataFrame\n",
    "        print(\"\\nTransposing SNP data...\")\n",
    "        processed_snp_data = snp_data_filtered.transpose()\n",
    "        print(f\"Transposed SNP data shape: {processed_snp_data.shape}\")\n",
    "        \n",
    "        # Create a mapping from StrainID to Clade\n",
    "        clade_map = clade_info.set_index('StrainID')['Clade'].to_dict()\n",
    "        \n",
    "        # Add Clade information to the transposed data\n",
    "        processed_snp_data['Clade'] = processed_snp_data.index.map(clade_map)\n",
    "        \n",
    "        # Reorder columns to put 'Clade' first\n",
    "        cols = [('Clade','')] + [col for col in processed_snp_data.columns if col != ('Clade','')]\n",
    "        processed_snp_data = processed_snp_data[cols]\n",
    "        \n",
    "        # Check for strains that didn't get a clade assigned (shouldn't happen with common_strains logic)\n",
    "        missing_clade = processed_snp_data[processed_snp_data['Clade'].isna()]\n",
    "        if not missing_clade.empty:\n",
    "            print(f\"Warning: {len(missing_clade)} strains could not be mapped to a clade:\")\n",
    "            print(missing_clade.index.tolist())\n",
    "            # Optionally remove strains with missing clades\n",
    "            processed_snp_data.dropna(subset=['Clade'], inplace=True)\n",
    "            print(f\"Removed {len(missing_clade)} strains with missing clades.\")\n",
    "        \n",
    "        print(\"\\nPreprocessing and merging complete.\")\n",
    "        print(\"First 5 rows of processed SNP data (Strains as rows, SNPs as columns):\")\n",
    "        # Displaying only first few SNP columns for brevity\n",
    "        print(processed_snp_data.iloc[:, :6].head())\n",
    "        \n",
    "else:\n",
    "    print(\"\\nSkipping Preprocessing: Required data (SNP or Clade) was not loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Genome Binning\n",
    "\n",
    "Divide the genome into non-overlapping 100kb bins based on the chromosome lengths. Calculate cumulative positions for plotting the concatenated genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_bins = None\n",
    "chromosome_boundaries = None\n",
    "chromosome_map = None\n",
    "chromosome_midpoints = None\n",
    "\n",
    "if genome_info is not None:\n",
    "    print(\"\\nStarting Genome Binning...\")\n",
    "    bin_size = 100000\n",
    "    bins_list = []\n",
    "    cumulative_pos = 0\n",
    "    chromosome_boundaries = [0] # Start boundary at 0\n",
    "    chromosome_map = {}\n",
    "    chromosome_midpoints = {}\n",
    "    \n",
    "    # Ensure correct data types\n",
    "    genome_info['Length'] = pd.to_numeric(genome_info['Length'], errors='coerce')\n",
    "    genome_info.dropna(subset=['Length'], inplace=True)\n",
    "    genome_info['Length'] = genome_info['Length'].astype(int)\n",
    "    \n",
    "    # Sort genome_info by chromosome name if needed (assuming natural sort order is desired)\n",
    "    # This might require more complex sorting if chromosome names are like chr1, chr10, chr2\n",
    "    # For TGME49_chrIa, TGME49_chrIb, etc., default sort should be okay.\n",
    "    chromosome_order = ['TGME49_chrIa', 'TGME49_chrIb', 'TGME49_chrII', 'TGME49_chrIII', 'TGME49_chrIV', 'TGME49_chrV', 'TGME49_chrVI', 'TGME49_chrVIIa', 'TGME49_chrVIIb','TGME49_chrVIII', 'TGME49_chrIX', 'TGME49_chrX', 'TGME49_chrXI', 'TGME49_chrXII']\n",
    "    genome_info_sorted = genome_info.sort_values(by='Chromosome', key=lambda x: x.map({name: i for i, name in enumerate(chromosome_order)})).reset_index(drop=True)\n",
    "    print(f\"Processing {len(genome_info_sorted)} chromosomes for binning.\")\n",
    "\n",
    "    for index, row in genome_info_sorted.iterrows():\n",
    "        chromosome = row['Chromosome']\n",
    "        length = row['Length']\n",
    "        chromosome_map[chromosome] = {'start_cumulative': cumulative_pos, 'length': length}\n",
    "        chromosome_midpoints[chromosome] = cumulative_pos + length / 2\n",
    "        \n",
    "        for bin_start in range(0, length, bin_size):\n",
    "            bin_end = min(bin_start + bin_size, length)\n",
    "            # Bin identifier combines chromosome and start position\n",
    "            bin_id = f\"{chromosome}_{bin_start+1}-{bin_end}\"\n",
    "            # Cumulative start position for this bin across the concatenated genome\n",
    "            bin_cumulative_start = cumulative_pos + bin_start\n",
    "            bin_cumulative_end = cumulative_pos + bin_end\n",
    "            \n",
    "            bins_list.append({\n",
    "                'BinID': bin_id,\n",
    "                'Chromosome': chromosome,\n",
    "                'BinStart': bin_start + 1, # 1-based start coordinate\n",
    "                'BinEnd': bin_end,\n",
    "                'CumulativeStart': bin_cumulative_start,\n",
    "                'CumulativeEnd': bin_cumulative_end\n",
    "            })\n",
    "        \n",
    "        # Update cumulative position for the next chromosome\n",
    "        cumulative_pos += length\n",
    "        chromosome_boundaries.append(cumulative_pos)\n",
    "            \n",
    "    genome_bins = pd.DataFrame(bins_list)\n",
    "    print(f\"\\nCreated {len(genome_bins)} genomic bins.\")\n",
    "    print(\"First 5 rows of genome_bins:\")\n",
    "    print(genome_bins.head())\n",
    "    print(\"\\nLast 5 rows of genome_bins:\")\n",
    "    print(genome_bins.tail())\n",
    "    print(f\"\\nChromosome boundaries (cumulative positions): {chromosome_boundaries}\")\n",
    "    print(f\"Total concatenated genome length: {cumulative_pos}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping Genome Binning: Genome information table was not loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clade Allele Profile Identification (Per Bin)\n",
    "\n",
    "For each 100kb bin, identify the SNPs within it. Then, for each clade (A-F), determine the representative allele profile based on the **most frequent allele** at each SNP position among strains belonging to that clade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clade_profiles = {}\n",
    "snps_in_bins = {} # Optional: store which SNPs fall in which bin\n",
    "unique_clades = []\n",
    "\n",
    "if processed_snp_data is not None and genome_bins is not None:\n",
    "    print(\"\\nStarting Clade Allele Profile Identification...\")\n",
    "    start_time_profiles = time.time()\n",
    "    \n",
    "    # Get unique clades from the processed data (ensure no NaN)\n",
    "    unique_clades = sorted(processed_snp_data['Clade'].dropna().unique())\n",
    "    print(f\"Identifying profiles for clades: {unique_clades}\")\n",
    "    \n",
    "    # Ensure the SNP columns in processed_snp_data have a MultiIndex\n",
    "    if not isinstance(processed_snp_data.columns, pd.MultiIndex):\n",
    "        print(\"Error: Columns of processed_snp_data are not a MultiIndex (Chromosome, Position). Cannot proceed.\")\n",
    "        # Attempt to recreate MultiIndex if snp_positions_df exists\n",
    "        if snp_positions_df is not None:\n",
    "             try:\n",
    "                 snp_cols = snp_positions_df.index\n",
    "                 # Select only SNP columns (exclude 'Clade')\n",
    "                 snp_data_only = processed_snp_data.drop(columns=['Clade'])\n",
    "                 snp_data_only.columns = snp_cols\n",
    "                 processed_snp_data = pd.concat([processed_snp_data[['Clade']], snp_data_only], axis=1)\n",
    "                 print(\"Successfully recreated MultiIndex columns.\")\n",
    "             except Exception as e:\n",
    "                 print(f\"Error recreating MultiIndex: {e}\")\n",
    "                 processed_snp_data = None # Mark as unusable\n",
    "        else:\n",
    "             processed_snp_data = None # Mark as unusable\n",
    "    \n",
    "if processed_snp_data is not None and genome_bins is not None: # Check again after potential index fix\n",
    "    # Get SNP columns (MultiIndex)\n",
    "    snp_columns = processed_snp_data.columns[1:] # Exclude 'Clade' column\n",
    "    \n",
    "    total_bins = len(genome_bins)\n",
    "    processed_count = 0\n",
    "    print_interval = max(1, total_bins // 10) # Print progress roughly 10 times\n",
    "    \n",
    "    # Iterate through each bin\n",
    "    for index, bin_info in genome_bins.iterrows():\n",
    "        bin_id = bin_info['BinID']\n",
    "        chrom = bin_info['Chromosome']\n",
    "        start = bin_info['BinStart']\n",
    "        end = bin_info['BinEnd']\n",
    "        \n",
    "        # Find SNPs within this bin\n",
    "        # Need to access the levels of the MultiIndex\n",
    "        snps_in_bin_mask = (snp_columns.get_level_values(0) == chrom) & \\\n",
    "                           (snp_columns.get_level_values(1) >= start) & \\\n",
    "                           (snp_columns.get_level_values(1) <= end)\n",
    "        \n",
    "        bin_snp_columns = snp_columns[snps_in_bin_mask]\n",
    "        snps_in_bins[bin_id] = bin_snp_columns.tolist() # Store SNP identifiers\n",
    "        \n",
    "        if not bin_snp_columns.empty:\n",
    "            clade_profiles[bin_id] = {}\n",
    "            # Get the SNP data just for this bin\n",
    "            # Ensure we only select columns that actually exist after filtering\n",
    "            existing_bin_snp_cols = [col for col in bin_snp_columns if col in processed_snp_data.columns]\n",
    "            if not existing_bin_snp_cols:\n",
    "                continue # Skip if somehow no SNP columns remain\n",
    "                \n",
    "            bin_snp_data = processed_snp_data[[('Clade','')] + existing_bin_snp_cols]\n",
    "            \n",
    "            # Calculate profile for each clade\n",
    "            for clade in unique_clades:\n",
    "                # Filter strains belonging to the current clade\n",
    "                clade_specific_data = bin_snp_data[bin_snp_data['Clade'] == clade]\n",
    "                \n",
    "                if not clade_specific_data.empty:\n",
    "                    # Calculate the mode (most frequent allele) for each SNP column\n",
    "                    # Drop 'Clade' column before calculating mode\n",
    "                    # mode() returns a DataFrame; we take the first row [0] in case of ties for mode\n",
    "                    # fillna('N') handles cases where a SNP might be all NaN for a clade\n",
    "                    # Use .infer_objects() to handle potential mixed types before mode calculation\n",
    "                    try:\n",
    "                        mode_profile = clade_specific_data.drop(columns=['Clade']).infer_objects().mode(axis=0, dropna=True).iloc[0].fillna('N') \n",
    "                        clade_profiles[bin_id][clade] = mode_profile # Store the profile (Pandas Series)\n",
    "                    except IndexError: # Handle cases where mode returns empty df (e.g., all NaNs)\n",
    "                         # Create a profile of 'N's with the correct index\n",
    "                         clade_profiles[bin_id][clade] = pd.Series('N', index=existing_bin_snp_cols)\n",
    "                         # print(f\"Debug: Mode calculation failed for bin {bin_id}, clade {clade}. Assigning 'N' profile.\")\n",
    "                    except Exception as e:\n",
    "                         print(f\"Error calculating mode for bin {bin_id}, clade {clade}: {e}\")\n",
    "                         # Create a profile of 'N's as fallback\n",
    "                         clade_profiles[bin_id][clade] = pd.Series('N', index=existing_bin_snp_cols)\n",
    "                # else: profile remains empty for this clade in this bin\n",
    "        # else: No SNPs in this bin, clade_profiles[bin_id] will not be created\n",
    "        \n",
    "        processed_count += 1\n",
    "        if processed_count % print_interval == 0 or processed_count == total_bins:\n",
    "            elapsed_time = time.time() - start_time_profiles\n",
    "            print(f\"  Processed {processed_count}/{total_bins} bins for profiles... ({elapsed_time:.2f}s elapsed)\")\n",
    "\n",
    "    end_time_profiles = time.time()\n",
    "    print(f\"\\nClade Allele Profile Identification complete. Took {end_time_profiles - start_time_profiles:.2f} seconds.\")\n",
    "    print(f\"Generated profiles for {len(clade_profiles)} bins with SNPs.\")\n",
    "    \n",
    "    # Example: Print profile for the first bin with data\n",
    "    first_bin_with_profile = next(iter(clade_profiles.items()), None)\n",
    "    if first_bin_with_profile:\n",
    "        bin_key, profiles = first_bin_with_profile\n",
    "        print(f\"\\nExample profile for bin '{bin_key}':\")\n",
    "        for clade, profile in profiles.items():\n",
    "            # Display only first few alleles of the profile Series\n",
    "            if isinstance(profile, pd.Series):\n",
    "                 print(f\"  Clade {clade}: {profile.head().to_list()}...\") \n",
    "            else:\n",
    "                 print(f\"  Clade {clade}: Profile is not a Series (type: {type(profile)}) \")\n",
    "            \n",
    "else:\n",
    "    print(\"\\nSkipping Profile Identification: Required data (processed SNP data or genome bins) is missing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Strain Bin Assignment\n",
    "\n",
    "Compare each strain's allele pattern within each bin to the representative clade profiles. Assign the bin to the clade with the highest **percentage identity**. If there's a tie, assign 'Mixed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_bin_assignments = None\n",
    "\n",
    "def calculate_percentage_identity(series1, series2):\n",
    "    \"\"\"Calculates percentage identity between two pandas Series, ignoring NaNs and 'N'.\"\"\"\n",
    "    # Ensure inputs are Series\n",
    "    if not isinstance(series1, pd.Series) or not isinstance(series2, pd.Series):\n",
    "        # print(f\"Debug: Invalid input types: {type(series1)}, {type(series2)}\")\n",
    "        return 0.0\n",
    "        \n",
    "    # Align series by index (SNPs)\n",
    "    aligned_s1, aligned_s2 = series1.align(series2, join='inner')\n",
    "    \n",
    "    if aligned_s1.empty: # No common SNPs\n",
    "        return 0.0\n",
    "        \n",
    "    # Convert to numpy arrays for faster comparison\n",
    "    arr1 = aligned_s1.to_numpy()\n",
    "    arr2 = aligned_s2.to_numpy()\n",
    "    \n",
    "    # Create masks for valid comparisons (ignore NaN, 'N', or other placeholders if necessary)\n",
    "    # Assuming 'N' and NaN are placeholders to ignore\n",
    "    valid_mask = (arr1 != 'N') & pd.notna(arr1) & (arr2 != 'N') & pd.notna(arr2)\n",
    "    \n",
    "    # Calculate matches only where both are valid\n",
    "    matches = (arr1[valid_mask] == arr2[valid_mask]).sum()\n",
    "    valid_comparisons = valid_mask.sum()\n",
    "    \n",
    "    if valid_comparisons == 0:\n",
    "        return 0.0 # Avoid division by zero if no valid positions to compare\n",
    "        \n",
    "    return (matches / valid_comparisons) * 100\n",
    "\n",
    "if processed_snp_data is not None and genome_bins is not None and clade_profiles:\n",
    "    print(\"\\nStarting Strain Bin Assignment...\")\n",
    "    start_time_assignment = time.time()\n",
    "    \n",
    "    strains_to_process = processed_snp_data.index\n",
    "    bin_ids = genome_bins['BinID'].tolist()\n",
    "    \n",
    "    # Initialize DataFrame for assignments\n",
    "    strain_bin_assignments = pd.DataFrame(index=strains_to_process, columns=bin_ids, dtype=object)\n",
    "    \n",
    "    total_assignments = len(strains_to_process) * len(bin_ids)\n",
    "    processed_assignments = 0\n",
    "    print_interval_assign = max(1, total_assignments // 20) # Print progress more frequently\n",
    "    \n",
    "    # Iterate through each strain\n",
    "    for strain_id in strains_to_process:\n",
    "        strain_data = processed_snp_data.loc[strain_id]\n",
    "        \n",
    "        # Iterate through each bin\n",
    "        for bin_id in bin_ids:\n",
    "            assignment = 'NoData' # Default if no SNPs or profiles\n",
    "            \n",
    "            if bin_id in clade_profiles and bin_id in snps_in_bins:\n",
    "                bin_snp_cols = snps_in_bins[bin_id]\n",
    "                \n",
    "                if bin_snp_cols: # Check if there are actually SNPs in this bin\n",
    "                    # Get the strain's pattern for the SNPs in this bin\n",
    "                    # Ensure columns exist in strain_data\n",
    "                    existing_snp_cols_in_strain = [col for col in bin_snp_cols if col in strain_data.index]\n",
    "                    if not existing_snp_cols_in_strain:\n",
    "                        assignment = 'NoData' # Strain has no data for SNPs in this bin\n",
    "                    else:\n",
    "                        strain_pattern = strain_data[existing_snp_cols_in_strain]\n",
    "                        \n",
    "                        # Compare with each clade profile for this bin\n",
    "                        identities = {}\n",
    "                        for clade, profile in clade_profiles[bin_id].items():\n",
    "                            if isinstance(profile, pd.Series):\n",
    "                                identities[clade] = calculate_percentage_identity(strain_pattern, profile)\n",
    "                            else:\n",
    "                                identities[clade] = 0.0 # Profile was invalid\n",
    "                        \n",
    "                        if identities: # If any identities were calculated\n",
    "                            max_identity = max(identities.values())\n",
    "                            # Check if max_identity is meaningfully high (e.g., > 0)\n",
    "                            if max_identity > 0.0:\n",
    "                                best_clades = [clade for clade, identity in identities.items() if identity == max_identity]\n",
    "                                \n",
    "                                if len(best_clades) == 1:\n",
    "                                    assignment = best_clades[0]\n",
    "                                else:\n",
    "                                    assignment = 'Mixed' # Tie\n",
    "                            else:\n",
    "                                assignment = 'NoMatch' # Max identity was 0 or less\n",
    "                        else:\n",
    "                            assignment = 'NoProfiles' # No valid profiles to compare against\n",
    "                # else: assignment remains 'NoData' (no SNPs in bin)\n",
    "            # else: assignment remains 'NoData' (no profiles for bin)\n",
    "            \n",
    "            strain_bin_assignments.loc[strain_id, bin_id] = assignment\n",
    "            \n",
    "            processed_assignments += 1\n",
    "            if processed_assignments % print_interval_assign == 0 or processed_assignments == total_assignments:\n",
    "                elapsed_time = time.time() - start_time_assignment\n",
    "                print(f\"    Assigned {processed_assignments}/{total_assignments} strain-bins... ({elapsed_time:.2f}s elapsed)\", end='\\r')\n",
    "\n",
    "    end_time_assignment = time.time()\n",
    "    print(f\"\\n\\nStrain Bin Assignment complete. Took {end_time_assignment - start_time_assignment:.2f} seconds.\")\n",
    "    print(\"First 5x5 of strain_bin_assignments matrix:\")\n",
    "    print(strain_bin_assignments.iloc[:5, :5])\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping Strain Bin Assignment: Required data (processed SNP data, genome bins, or clade profiles) is missing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plotting\n",
    "\n",
    "Visualize the strain bin assignments as a heatmap. Strains are sorted by clade, and bins represent the concatenated genome.\n",
    "\n",
    "Virulence factors of interest:\n",
    "1- ROP18    TGME49_chrVIIa:1,513,497..1,516,225(-)\n",
    "2- ROP16\n",
    "3- GRA15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if strain_bin_assignments is not None and processed_snp_data is not None and genome_bins is not None and chromosome_boundaries is not None:\n",
    "    print(\"\\nStarting Plotting...\")\n",
    "    \n",
    "    # --- Prepare data for plotting ---\n",
    "    \n",
    "    # 1. Get Clade order and define colors\n",
    "    # Use the unique clades found earlier, plus special categories\n",
    "    all_categories = unique_clades + ['Mixed', 'NoMatch', 'NoProfiles', 'NoData']\n",
    "    # Define a color map (using a standard map and adding specific colors for special cases)\n",
    "    # Example: Use 'tab10' for clades, gray shades for others\n",
    "    cmap_clades = plt.get_cmap('tab10', len(unique_clades))\n",
    "    color_map = {clade: cmap_clades(i) for i, clade in enumerate(unique_clades)}\n",
    "    color_map['Mixed'] = 'lightgrey'\n",
    "    color_map['NoMatch'] = 'grey'\n",
    "    color_map['NoProfiles'] = 'darkgrey'\n",
    "    color_map['NoData'] = 'white'\n",
    "    \n",
    "    # 2. Create a numerical matrix for imshow\n",
    "    category_to_int = {category: i for i, category in enumerate(all_categories)}\n",
    "    int_to_category = {i: category for category, i in category_to_int.items()}\n",
    "    \n",
    "    # Map assignments to integers, handling potential new/unexpected values\n",
    "    default_int = category_to_int['NoData'] # Default to NoData color\n",
    "    numerical_matrix = strain_bin_assignments.map(lambda x: category_to_int.get(x, default_int))\n",
    "    \n",
    "    # 3. Sort strains by Clade\n",
    "    # Get original clade for each strain\n",
    "    strain_clades_original = processed_snp_data['Clade']\n",
    "    # Align index with assignment matrix and sort\n",
    "    sorted_strains_index = strain_clades_original.loc[numerical_matrix.index].sort_values().index\n",
    "    numerical_matrix_sorted = numerical_matrix.loc[sorted_strains_index]\n",
    "    \n",
    "    # --- Create the plot ---\n",
    "    fig, ax = plt.subplots(figsize=(20, 10)) # Adjust figure size as needed\n",
    "    \n",
    "    # Create the colormap and norm for imshow\n",
    "    cmap_list = [color_map[int_to_category[i]] for i in range(len(all_categories))]\n",
    "    custom_cmap = mcolors.ListedColormap(cmap_list)\n",
    "    norm = mcolors.BoundaryNorm(np.arange(len(all_categories) + 1) - 0.5, len(all_categories))\n",
    "    \n",
    "    # Display the heatmap\n",
    "    im = ax.imshow(numerical_matrix_sorted, aspect='auto', cmap=custom_cmap, norm=norm, interpolation='none')\n",
    "    \n",
    "    # Add horizontal lines between strains\n",
    "    num_strains = len(sorted_strains_index)\n",
    "    ax.hlines(np.arange(num_strains - 1) + 0.5, -0.5, numerical_matrix_sorted.shape[1] - 0.5, color='white', lw=1, alpha=1)\n",
    "    \n",
    "    # Add chromosome boundary lines\n",
    "    for boundary in chromosome_boundaries[1:-1]: # Exclude start and end boundaries\n",
    "        # Find the index corresponding to the cumulative boundary\n",
    "        # This requires mapping cumulative position back to bin index\n",
    "        boundary_bin_index = genome_bins[genome_bins['CumulativeEnd'] <= boundary].index.max() \n",
    "        if pd.notna(boundary_bin_index):\n",
    "             # Draw line between bins\n",
    "             ax.vlines(boundary_bin_index + 0.5, -0.5, len(sorted_strains_index) - 0.5, color='black', lw=3)\n",
    "        \n",
    "        # --- Add vertical lines for genes of interest ---\n",
    "        genes_of_interest = {\n",
    "            'ROP18': {'chr': 'TGME49_chrVIIa', 'start': 1513497, 'end': 1516225, 'color': 'red'},\n",
    "            'GRA15': {'chr': 'TGME49_chrX', 'start': 7286296, 'end': 7289756, 'color': 'red'},\n",
    "            'ROP16': {'chr': 'TGME49_chrVIIb', 'start': 1053320, 'end': 1056800, 'color': 'red'}\n",
    "        }\n",
    "\n",
    "        if chromosome_map and genome_bins is not None:\n",
    "            num_strains = len(sorted_strains_index) # Get number of strains for text positioning\\n\n",
    "            for gene_name, info in genes_of_interest.items():\n",
    "                if info['chr'] in chromosome_map:\n",
    "                    chrom_start_cumulative = chromosome_map[info['chr']]['start_cumulative']\n",
    "                    gene_start_cumulative = chrom_start_cumulative + info['start']\n",
    "\n",
    "                    # Find the bin index containing the gene start position\n",
    "                    # We want the index of the bin where CumulativeStart <= gene_start_cumulative < CumulativeEnd\n",
    "                    gene_bin_index_match = genome_bins[\n",
    "                        (genome_bins['CumulativeStart'] <= gene_start_cumulative) &\n",
    "                        (genome_bins['CumulativeEnd'] > gene_start_cumulative)\n",
    "                    ]\n",
    "\n",
    "                    if not gene_bin_index_match.empty:\n",
    "                        gene_bin_index = gene_bin_index_match.index[0]\n",
    "                        # Draw line at the start of the bin containing the gene start\n",
    "                        ax.axvline(gene_bin_index - 0.5, color=info['color'], linestyle='--', lw=1.5, alpha=0.8)\n",
    "                        # Add text label above the plot, slightly offset from the top edge\n",
    "                        ax.text(gene_bin_index, -0.02 * num_strains, gene_name, color=info['color'], ha='center', va='bottom', fontsize=8, rotation=90)\n",
    "                    else:\n",
    "                        print(f\"Warning: Could not find bin index for gene {gene_name} at cumulative position {gene_start_cumulative}\")\n",
    "                else:\n",
    "                     print(f\"Warning: Chromosome {info['chr']} for gene {gene_name} not found in chromosome_map.\")\n",
    "        # -------------------------------------------------\n",
    "        \n",
    "    # Set labels and title\n",
    "    ax.set_yticks(np.arange(len(sorted_strains_index)))\n",
    "    ax.set_yticklabels(sorted_strains_index, fontsize=8) # Adjust fontsize if needed\n",
    "    ax.set_ylabel(\"Strains (Sorted by Clade)\")\n",
    "    \n",
    "    # Set x-axis ticks to chromosome midpoints\n",
    "    chrom_tick_positions = []\n",
    "    chrom_tick_labels = []\n",
    "    if chromosome_map and genome_bins is not None:\n",
    "        for chrom, data in chromosome_map.items():\n",
    "             midpoint_cumulative = data['start_cumulative'] + data['length'] / 2\n",
    "             # Find the bin index closest to the midpoint\n",
    "             midpoint_bin_index = (genome_bins['CumulativeStart'] - midpoint_cumulative).abs().idxmin()\n",
    "             chrom_tick_positions.append(midpoint_bin_index)\n",
    "             # Shorten chromosome names for labels if needed\n",
    "             label = chrom.replace('TGME49_chr', '')\n",
    "             chrom_tick_labels.append(label)\n",
    "        ax.set_xticks(chrom_tick_positions)\n",
    "        ax.set_xticklabels(chrom_tick_labels, rotation=90, fontsize=8)\n",
    "    else:\n",
    "        ax.set_xlabel(\"Genomic Bins (Concatenated Chromosomes)\")\n",
    "        \n",
    "    #ax.set_title(\"Haplogroup Assignments across Toxoplasma gondii Genome Bins (100kb)\")\n",
    "    \n",
    "    # Create custom legend\n",
    "    patches = [mpatches.Patch(color=color_map[category], label=category) for category in all_categories]\n",
    "    ax.legend(handles=patches, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0., title=\"Clade\")\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1]) # Adjust layout to make space for legend\n",
    "    \n",
    "    # Save the plot\n",
    "    print(f\"\\nSaving plot to {output_plot_file}...\")\n",
    "    try:\n",
    "        plt.savefig(output_plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(\"Plot saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving plot: {e}\")\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    # --- Create and save separate plots for each Chromosome ---\n",
    "    for chr_target in genome_info_sorted['Chromosome']:\n",
    "        print(f\"\\nGenerating plot for Chromosome {chr_target}...\")\n",
    "        #chr_target = 'TGME49_chrVIIa'\n",
    "        output_chr_plot_file = f\"{chr_target}_haplogroups.pdf\"\n",
    "        \n",
    "        # Filter data for the target chromosome\n",
    "        chr_bins = genome_bins[genome_bins['Chromosome'] == chr_target].copy()\n",
    "        if not chr_bins.empty:\n",
    "            # Reset index for easier mapping of relative bin index\n",
    "            chr_bins.reset_index(drop=True, inplace=True)\n",
    "            chr_bin_ids = chr_bins['BinID'].tolist()\n",
    "            strain_bin_assignments_chr = strain_bin_assignments[chr_bin_ids]\n",
    "            numerical_matrix_chr = strain_bin_assignments_chr.map(lambda x: category_to_int.get(x, default_int))\n",
    "            numerical_matrix_chr_sorted = numerical_matrix_chr.loc[sorted_strains_index]\n",
    "            \n",
    "            # Create new figure for this chromosome\n",
    "            fig_chr, ax_chr = plt.subplots(figsize=(8, 10)) # Adjust size as needed\n",
    "            \n",
    "            # Display heatmap for the chromosome\n",
    "            im_chr = ax_chr.imshow(numerical_matrix_chr_sorted, aspect='auto', cmap=custom_cmap, norm=norm, interpolation='none')\n",
    "            \n",
    "            # Add horizontal lines\n",
    "            ax_chr.hlines(np.arange(num_strains - 1) + 0.5, -0.5, numerical_matrix_chr_sorted.shape[1] - 0.5, color='white', lw=1, alpha=1)\n",
    "            \n",
    "            # Add Genes of interest line (relative position)\n",
    "            for gene in genes_of_interest.keys():\n",
    "                gene_info = genes_of_interest[gene]\n",
    "                if gene_info['chr'] == chr_target:\n",
    "                    gene_start_pos = gene_info['start']\n",
    "                    # Find bin index within the filtered chr_bins dataframe\n",
    "                    gene_bin_match = chr_bins[\n",
    "                        (chr_bins['BinStart'] <= gene_start_pos) &\n",
    "                        (chr_bins['BinEnd'] > gene_start_pos)\n",
    "                    ]\n",
    "                    if not gene_bin_match.empty:\n",
    "                        # Use the index from the filtered (and reset) chr_bins dataframe\n",
    "                        gene_bin_index_relative = gene_bin_match.index[0]\n",
    "                        ax_chr.axvline(gene_bin_index_relative - 0.5, color=gene_info['color'], linestyle='--', lw=1.5, alpha=0.8)\n",
    "                        ax_chr.text(gene_bin_index_relative, -0.02 * num_strains, gene, color=gene_info['color'], ha='center', va='bottom', fontsize=8, rotation=90)\n",
    "                    else:\n",
    "                        print(f\"Warning: Could not find bin index for {gene} within {chr_target}.\")\n",
    "\n",
    "            # Set labels and title for chrVIIa plot\n",
    "            ax_chr.set_yticks(np.arange(len(sorted_strains_index)))\n",
    "            ax_chr.set_yticklabels(sorted_strains_index, fontsize=8)\n",
    "            ax_chr.set_ylabel(\"Strains (Sorted by Clade)\")\n",
    "            \n",
    "            # Set x-axis ticks based on bin start positions for this chromosome\n",
    "            tick_indices = np.linspace(0, len(chr_bins) - 1, num=10, dtype=int) # Show ~10 ticks\n",
    "            tick_labels = [f\"{chr_bins.loc[i, 'BinStart']:,}\" for i in tick_indices]\n",
    "            ax_chr.set_xticks(tick_indices)\n",
    "            ax_chr.set_xticklabels(tick_labels, rotation=45, ha='right', fontsize=8)\n",
    "            ax_chr.set_xlabel(f\"Position on {chr_target} (bp)\")\n",
    "            \n",
    "            ax_chr.set_title(f\"Haplogroup Assignments across {chr_target} Bins (100kb)\", pad=40)\n",
    "            \n",
    "            # Add legend\n",
    "            ax_chr.legend(handles=patches, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0., title=\"Clade\")\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "            \n",
    "            # Save the chrVIIa plot\n",
    "            print(f\"\\nSaving plot to {output_chr_plot_file}...\")\n",
    "            try:\n",
    "                fig_chr.savefig(output_chr_plot_file, dpi=300, bbox_inches='tight') # Use fig_chr here\n",
    "                print(f\"Chromosome {chr_target} plot saved successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving chromosome {chr_target} plot: {e}\")\n",
    "                \n",
    "            plt.show() # Show the chrVIIa plot as well\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nSkipping plot generation for {chr_target}: No bins found for this chromosome.\")\n",
    "    # ---------------------------------------------------------\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping Plotting: Required data is missing.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tghsus2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
